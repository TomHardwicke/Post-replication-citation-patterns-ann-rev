---
title: "Post-replication citation curves for Replicability, Robustness, and Reproducibility paper"
description: |
  This script takes data from the project "Post-replication citation patterns in psychology" (Hardwicke et al., 2021) and writes reproducible text and a citation curve graph for the "Replicability, Robustness, and Reproducibility in Psychological Science" (Nosek et al.) paper.
author:
  - name: Tom Hardwicke 
    affiliation: Univeristy of Amsterdam
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r load_packages, warning=F}
# load packages
library(knitr) # for literate programming
library(papaja) # for apa theme
library(tidyverse) # for data munging
library(here) # for finding files
library(ggpubr) # for arranging plots
```

```{r load_data}
# loads the processed data files
load(here('data','d_citations.rds'))
load(here('data','d_reference.rds'))
load(here('data','d_contentAnalysis.rds'))
```

```{r load_functions}
# load custom functions
source(here('analysis','functions.R'))
```

```{r add_standardized_citation_counts}
# identify the five different case studies we are looking at
caseNames <- c('baumeister', 'strack')
replicationYears <- c(2016, 2016)

# set up some colour palettes
purple <- '#481567FF'
teal <- '#33638DFF'
green <- '#20A387FF'
ruby <- '#d14c6f'
tan <- '#fcb785'
  
p1 <- c('lightgrey','darkgrey',purple,teal,green)
p2 <- c('lightgrey',ruby,tan)

# summarizes data at the year level for each case and adds standardized citation counts for target citations and reference class citations
d_summary <- data.frame() # create empty list to hold data frames for each case
for(i in seq(1,2)){ # loop through cases
  d <- standardizeCitations(
    thisCase = caseNames[i],
    citationData = d_citations %>% filter(case == caseNames[i]), 
    referenceData = d_reference %>% filter(case == caseNames[i]),
    contentData = d_contentAnalysis %>% filter(case == caseNames[i]),
    replicationYear = replicationYears[i])
  d_summary <- bind_rows(d_summary, d) # append to dataframe
}

# summarise counter-argument data
ca_fav <- d_contentAnalysis %>% 
  filter(citesReplication == T) %>% 
  filter(citationClassificationAgreed == 'favourable') %>%
  group_by(case, counterArguments, .drop = F) %>%
  summarise(n = n()) %>%
  mutate(percent = round(n/sum(n)*100,0)) %>%
  select(-n)
```


Scientistsâ€™ response to replications may also be reflected in how original studies are cited. One examination of post-replication citation patterns in psychology suggests that even clearly contradictory replication results may only have a modest impact on how original studies are appraised in subsequent academic literature (Figure 1; Hardwicke et al., 2021). In the case of ego depletion, there was a small increase in favorable citations (`r d_summary %>% filter(case == 'baumeister' & pubYear == '2015') %>% mutate(value = round(favourable_prop*100,0)) %>% pull(value)`% to `r d_summary %>% filter(case == 'baumeister' & pubYear == 'post-replication') %>% mutate(value = round(favourable_prop*100,0)) %>% pull(value)`%) to Baumeister and colleagues (1998) and a small increase in unfavourable citations (`r d_summary %>% filter(case == 'baumeister' & pubYear == '2015') %>% mutate(value = round(unfavourable_prop*100,0)) %>% pull(value)`% to `r d_summary %>% filter(case == 'baumeister' & pubYear == 'post-replication') %>% mutate(value = round(unfavourable_prop*100,0)) %>% pull(value)`%) from pre-replication (2015) to post-replication (2017-2019). In the case of Strack and colleagues (1988), another classic finding with a prominent failure to replicate (Wagenmakers et al., 2016), there was a decrease in favourable citations (`r d_summary %>% filter(case == 'strack' & pubYear == '2015') %>% mutate(value = round(favourable_prop*100,0)) %>% pull(value)`% to `r d_summary %>% filter(case == 'strack' & pubYear == 'post-replication') %>% mutate(value = round(favourable_prop*100,0)) %>% pull(value)`%) and a small increase in unfavourable citations (`r d_summary %>% filter(case == 'strack' & pubYear == '2015') %>% mutate(value = round(unfavourable_prop*100,0)) %>% pull(value)`% to `r d_summary %>% filter(case == 'strack' & pubYear == 'post-replication') %>% mutate(value = round(unfavourable_prop*100,0)) %>% pull(value)`%). These suggest modest corrective effects and imply considerable perpetuation of belief in the credibility of the original findings despite the contradictory replication results. Even clearly contradictory replication results do not necessarily undermine the credibility of an original finding (Collins, 1992; Earp & Trafimow, 2015; Maxwell et al., 2015); however, one might expect relevant counterevidence to be acknowledged and addressed with explicit argumentation. However, Hardwicke et al. observed substantial citation bias: only `r d_summary %>% filter(case == 'strack' & pubYear == 'post-replication') %>% mutate(value = round(citesRep_yes_prop*100,0)) %>% pull(value)`% of post-replication articles citing Strack and colleagues (1988) and `r d_summary %>% filter(case == 'baumeister' & pubYear == 'post-replication') %>% mutate(value = round(citesRep_yes_prop*100,0)) %>% pull(value)`% of those citing Baumeister and colleagues (1998) also cited the respective large-scale replication. Of those articles that cited the original study favorably and cited the replication, a principled defence of the original study appeared in `r ca_fav %>% filter(case == 'strack', counterArguments == TRUE) %>% pull(percent)`% and `r ca_fav %>% filter(case == 'baumeister', counterArguments == TRUE) %>% pull(percent)`% of articles respectively. Thus, in these case studies, there is neglect of relevant replication evidence in post-replication citation patterns.

```{r citationCurves, fig.width=12, fig.height=8, fig.path='figs/', dev=c('png', 'pdf')}
ggarrange(citationCurve('strack', thisTitle = 'Strack et al. (1988)', standardized = T, plotReference = T, areaPlot = "classification"),
          citationCurve('baumeister', thisTitle = 'Baumeister et al. (1998)', standardized = T, plotReference = T, areaPlot = "classification"),
          nrow = 2, ncol = 1, common.legend = T) %>%
    annotate_figure(
    left = text_grob("Standardized citation count", rot = 90, size = 20),
    bottom = text_grob("Publication year", size = 20))
```







